{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de894a5c-5796-4c5c-991e-bbf8c6369424",
   "metadata": {},
   "source": [
    "# <p style=\"background-color:purple; font-family:calibri; color:white; font-size:150%; text-align:center; border-radius:15px 50px;\">Breast Cancer Risk Prediction</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ba1e76-53c1-4a16-97c0-6914456b6065",
   "metadata": {},
   "source": [
    "<a id=\"contents_tabel\"></a> \n",
    "<h3 align=\"left\"><font color=purple>Table of Contents:</font></h3>\n",
    "\n",
    "* [Step 1 | Import Libraries](#import)\n",
    "* [Step 2 | Read Dataset](#read)\n",
    "* [Step 3 | Sanity check of data](#check)\n",
    "* [Step 4 | Dataset Overview](#overview)\n",
    "    - [Step 4.1 | Dataset Basic Information](#basic)\n",
    "    - [Step 4.2 | Summary Statistics for Numerical Variables](#num_statistics)\n",
    "    - [Step 4.3 | Summary Statistics for Categorical Variables](#cat_statistics)\n",
    "* [Step 5 | Missing Value Treatment](#missing)    \n",
    "* [Step 6 | Categorical Features Encoding](#encoding)\n",
    "* [Step 7 | EDA](#eda)\n",
    "    - [Step 7.1 | Univariate Analysis](#univariate)\n",
    "    - [Step 7.2 | Bivariate Analysis](#bivariate)\n",
    "        - [Step 7.2.1 | Numerical Features vs Overall Survival Status](#num_target)\n",
    "        - [Step 7.2.2 | Categorical Features vs Overall Survival Status](#cat_target)\n",
    "* [Step 8 | Data Preprocessing](#preprocessing)\n",
    "    - [Step 8.1 | Outlier Treatment](#outlier)\n",
    "    - [Step 8.2 | Transforming Skewed Features](#transform)   \n",
    "* [Step 9 | Survival Analysis](#survival)\n",
    "    - [Step 9.1 | Kaplan-Meier Survival Curve](#kp)\n",
    "* [Step 10 | Decision Tree Model Building](#dt)    \n",
    "* [Step 11 | Random Forest Model Building](#rf)\n",
    "    - [Step 11.1 | RF Base Model Definition](#rf_base)\n",
    "    - [Step 11.2 | RF Hyperparameter Tuning](#rf_hp)\n",
    "    - [Step 11.3 | RF Model Evaluation](#rf_eval)\n",
    "* [Step 12 | Logistic Regression Model Building](#logistic)\n",
    "    - [Step 12.1 | Logistic Base Model Definition](#logistic_base)\n",
    "    - [Step 12.2 | Logistic Hyperparameter Tuning](#logistic_hp)\n",
    "    - [Step 12.3 | Logistic Model Evaluation](#logistic_eval)\n",
    "* [Step 13 | SVM Model Building](#svm)\n",
    "    - [Step 13.1 | SVM Base Model Definition](#svm_base)\n",
    "    - [Step 13.2 | SVM Hyperparameter Tuning](#svm_hp)\n",
    "    - [Step 13.3 | SVM Model Evaluation](#svm_eval)\n",
    "* [Step 14 | Conclusion](#conclusion)\n",
    "* [Step 15 | Prediction](#prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf6e4cd-35cd-410b-bad3-c23e098a54dc",
   "metadata": {},
   "source": [
    "<a id=\"import\"></a>\n",
    "# <p style=\"background-color:purple; font-family:calibri; color:white; font-size:150%; text-align:center; border-radius:15px 50px;\">Step 1 | Import Libraries</p>\n",
    " [Table of Contents](#contents_tabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6dcb7f0-02ca-4cb1-b9e5-cbe051b948e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib.colors import ListedColormap\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.impute import KNNImputer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import skew\n",
    "from scipy.stats import boxcox\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from lifelines import KaplanMeierFitter\n",
    "from lifelines import CoxPHFitter\n",
    "from lifelines.fitters.coxph_fitter import CoxPHFitter\n",
    "from lifelines.statistics import proportional_hazard_test\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML\n",
    "from lifelines.statistics import multivariate_logrank_test   \n",
    "from lifelines.statistics import logrank_test\n",
    "\n",
    "from lifelines.utils import concordance_index as cindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50bc86e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the resolution of the plotted figures\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "\n",
    "# Configure Seaborn plot styles: Set background color and use dark| grid\n",
    "sns.set(rc={'axes.facecolor': '#faded9'}, style='darkgrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971c5dde-7fd0-4a95-937b-7c562bb9be8e",
   "metadata": {},
   "source": [
    "<a id=\"read\"></a> \n",
    "# <p style=\"background-color:purple; font-family:calibri; color:white; font-size:150%; text-align:center; border-radius:15px 50px;\">Step 2 | Read Dataset</p>\n",
    " [Table of Contents](#contents_tabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b886647b-d785-47e9-883d-5344d92f0c2a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:Breast Cancer METABRIC.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Read datasetdf= \u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39m read_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:Breast Cancer METABRIC.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m df\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    945\u001b[0m )\n\u001b[0;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1706\u001b[0m     f,\n\u001b[0;32m   1707\u001b[0m     mode,\n\u001b[0;32m   1708\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1709\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1710\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1711\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1712\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1713\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1714\u001b[0m )\n\u001b[0;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    864\u001b[0m             handle,\n\u001b[0;32m    865\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    866\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    867\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    868\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    869\u001b[0m         )\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:Breast Cancer METABRIC.csv'"
     ]
    }
   ],
   "source": [
    "# Read datasetdf= \n",
    "df = pd. read_csv(\"C:Breast Cancer METABRIC.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f134348d-f9ce-4695-9713-3f4e6d2022d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#head \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf443fea-1758-4afe-982e-a51259a6d63e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#tail \n",
    "df.tail()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6154fa27-32b2-4058-9b71-099e93323f80",
   "metadata": {},
   "source": [
    "<a id=\"check\"></a> \n",
    "# <p style=\"background-color:purple; font-family:calibri; color:white; font-size:150%; text-align:center; border-radius:15px 50px;\">Step 3 | Sanity check of data</p>\n",
    " [Table of Contents](#contents_tabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf4b577-a424-45ed-8155-6057fb3fedfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#shape\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57aa8f13-e4a8-4ccd-9730-7ea0b7bc2df6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#info\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc52afa-e858-4a57-8555-ca9041c7bf01",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#finding missing values \n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81999d8e-902f-4281-ab3c-3a7f3189c53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding duplicates \n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a543bc1-66ad-47ce-9ef2-bf24571fc0e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#identifying garbage values\n",
    "for i in df.select_dtypes(include= \"object\").columns:\n",
    "    print(df[i].value_counts())\n",
    "    print(\"***\"*10) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aeee57c-fd46-4e91-ad01-d1522e57d860",
   "metadata": {},
   "source": [
    "<a id=\"overview\"></a>\n",
    "# <p style=\"background-color:purple; font-family:calibri; color:white; font-size:150%; text-align:center; border-radius:15px 50px;\">Step 4 | Dataset Overview</p>\n",
    " [Table of Contents](#contents_tabel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b2f74f-f073-4aa3-ab1b-a7d244d55fa5",
   "metadata": {},
   "source": [
    "<a id=\"basic\"></a>\n",
    "# <p style=\"background-color:purple; font-family:calibri; color:white; font-size:150%; text-align:center; border-radius:15px 50px;\">Step 4.1 | Dataset Basic Information</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97b1c09-26e3-4a45-9e96-11bbbbcddab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42cd2ff7",
   "metadata": {},
   "source": [
    "<div style=\"border-radius:10px; padding: 15px; ; font-size:100%; text-align:left\">\n",
    "\n",
    "<h2 align=\"left\"><font color=white>Dataset Description:</font></h2>\n",
    "\n",
    "| __Patient ID:__ | Unique identifier for each patient.|\n",
    "\n",
    "| __Age at Diagnosis:__ | Age of the patient when diagnosed with cancer.|\n",
    "\n",
    "| __Type of Breast Surgery:__ | The type of surgery performed on the breast, such as mastectomy or lumpectomy.|\n",
    "\n",
    "| __Cancer Type:__ | General classification of the cancer type (e.g., invasive ductal carcinoma).|\n",
    "\n",
    "| __Cancer Type Detailed:__ | More specific classification of the cancer type.|\n",
    "\n",
    "| __Cellularity:__ | The degree of cellularity of the tumor, often used in pathology to describe the proportion of cells versus other components in a tissue sample.|\n",
    "\n",
    "| __Chemotherapy:__ | Indicates whether the patient received chemotherapy (Yes/No).|\n",
    "\n",
    "| __Pam50 + Claudin-low subtype:__ | Subtypes based on gene expression profiling, including Pam50 and Claudin-low classifications.|\n",
    "\n",
    "| __Cohort:__ | The group or study cohort to which the patient belongs.|\n",
    "\n",
    "| __ER status measured by IHC:__ | Estrogen receptor status as measured by Immunohistochemistry (IHC) (e.g., positive or negative).|\n",
    "\n",
    "| __ER Status:__ | Estrogen receptor status (e.g., positive, negative).|\n",
    "\n",
    "| __Neoplasm Histologic Grade:__ | Histologic grade of the neoplasm, indicating how much the tumor cells differ from normal cells.|\n",
    "\n",
    "| __HER2 status measured by SNP6:__ | HER2 (human epidermal growth factor receptor 2) status measured by SNP (single nucleotide polymorphism) analysis.|\n",
    "\n",
    "| __HER2 Status:__ | HER2 receptor status (e.g., positive, negative).|\n",
    "\n",
    "| __Tumor Other Histologic Subtype:__ | Other histologic subtypes of the tumor not covered by main classifications.|\n",
    "\n",
    "| __Hormone Therapy:__ | Indicates whether the patient received hormone therapy (Yes/No).|\n",
    "\n",
    "| __Inferred Menopausal State:__ | Menopausal state inferred based on age and clinical criteria (e.g., premenopausal, postmenopausal).|\n",
    "\n",
    "| __Integrative Cluster:__ | Classification based on integrative clustering of genomic data.|\n",
    "\n",
    "| __Primary Tumor Laterality:__ | The side of the body where the primary tumor is located (left or right).|\n",
    "\n",
    "| __Lymph nodes examined positive:__ | Number of lymph nodes that tested positive for cancer.|\n",
    "\n",
    "| __Mutation Count:__ | Total number of genetic mutations identified in the tumor.|\n",
    "\n",
    "| __Nottingham prognostic index:__ | Prognostic score based on tumor size, lymph node status, and histologic grade.|\n",
    "\n",
    "| __Oncotree Code:__ | A code that represents the type of cancer based on the OncoTree classification.|\n",
    "\n",
    "| __Overall Survival (Months):__ | The overall survival time of the patient in months.|\n",
    "\n",
    "| __Overall Survival Status:__ | Indicates whether the patient is alive or deceased.|\n",
    "\n",
    "| __PR Status:__ | Progesterone receptor status (e.g., positive, negative).|\n",
    "\n",
    "| __Radio Therapy:__ | Indicates whether the patient received radiotherapy (Yes/No).|\n",
    "\n",
    "| __Relapse Free Status (Months):__ | Time in months the patient remained free from cancer relapse.|\n",
    "\n",
    "| __Relapse Free Status:__ | Indicates whether the patient has had a relapse of cancer (Yes/No).|\n",
    "\n",
    "| __Sex:__ | The sex of the patient (male or female).|\n",
    "\n",
    "| __3-Gene classifier subtype:__ | Subtypes based on the expression of three specific genes.|\n",
    "\n",
    "| __Tumor Size:__ | Size of the primary tumor.|\n",
    "\n",
    "| __Tumor Stage:__ | Stage of the tumor, indicating the extent of cancer spread.|\n",
    "\n",
    "| __Patient's Vital Status:__ | Indicates whether the patient is alive or deceased at the last follow-up.|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d27be94-4538-4924-b62e-e6571ce3df7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Display a concise summary of the dataframe\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e651b2-0009-4897-af62-b002c43e489c",
   "metadata": {},
   "source": [
    "# Inferences:\n",
    "### Number of Entries: \n",
    "The dataset consists of 2509 entries, ranging from index 0 to 2508.\n",
    "\n",
    "### Columns: \n",
    "There are 34 columns in the dataset corresponding to various attributes of the patients and results of tests.\n",
    "\n",
    "### Data Types:\n",
    "There are 24 columns of object data type and 10 columns of float data type\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55b4379-2675-47dd-a880-6b9f73918a0f",
   "metadata": {},
   "source": [
    "<a id=\"num_statistics\"></a>\n",
    "# <p style=\"background-color:purple; font-family:calibri; color:white; font-size:150%; text-align:center; border-radius:15px 50px;\">Step 4.2 | Summary Statistics for Numerical Variables</p>\n",
    " [Table of Contents](#contents_tabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5255f4f3-469e-4b4a-8832-5d11a0176590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the summary statistics for numerical variables\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650e9561-d00c-4881-a8c5-b602c3a466aa",
   "metadata": {},
   "source": [
    "##  Numerical Features:\n",
    "####    __`Age at Diagnosis`__: Age of the patient when diagnosed with cancer.\n",
    "####    __`Lymph nodes examined positive`__: Number of lymph nodes that tested positive for cancer.\n",
    "####   __`Mutation Count`__: Total number of genetic mutations identified in the tumor.\n",
    "####    __`Tumor Size`__: Size of the primary tumor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68bf695",
   "metadata": {},
   "source": [
    "Note: Based on the data types and the feature explanations, we can see that 6 columns ('Cohort', 'Neoplasm Histologic Grade','Nottingham prognostic index', 'Overall Survival (Months)','Relapse Free Status (Months)', 'Tumor Stage') are indeed numerical in terms of data type, but categorical in terms of their semantics. These features should be converted to string (object) data type for proper analysis and interpretation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7fbbb2-669b-4b77-9379-2f4b4d69774d",
   "metadata": {},
   "source": [
    "<a id=\"cat_statistics\"></a>\n",
    "# <p style=\"background-color:purple; font-family:calibri; color:white; font-size:150%; text-align:center; border-radius:15px 50px;\">Step 4.3 | Summary Statistics for Categorical Variables</p>\n",
    " [Table of Contents](#contents_tabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff4bd50-fffc-448d-a125-cc3463fe65e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the summary statistics for categorical variables\n",
    "df.describe(include='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf78e1b-5b0e-4831-ad6f-d04f7aa35cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c64c4bd-c47c-4556-9555-cf9a464cb01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_columns = df.select_dtypes(include=['object']).columns \n",
    "print(object_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8fe803-c021-47c5-a3ac-a547fae4b333",
   "metadata": {},
   "outputs": [],
   "source": [
    "float_columns = df.select_dtypes(include=\"float64\").columns\n",
    "print(float_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2492255",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define the continuous features\n",
    "continuous_features = ['Age at Diagnosis', 'Lymph nodes examined positive', 'Mutation Count','Tumor Size']\n",
    "\n",
    "# Identify the features to be converted to object data type\n",
    "features_to_convert = [feature for feature in df.columns if feature not in continuous_features]\n",
    "\n",
    "# Convert the identified features to object data type\n",
    "df[features_to_convert] = df[features_to_convert].astype('object')\n",
    "\n",
    "\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9c8265-e130-4c4c-9c38-e752dc8ed629",
   "metadata": {},
   "source": [
    "By now Out of 34 columns, 30 columns are of object data types based on their semantics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f3d9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_columns = df.select_dtypes(include=['object']).columns \n",
    "print(object_columns)\n",
    "object_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2837390d",
   "metadata": {},
   "outputs": [],
   "source": [
    "float_columns = df.select_dtypes(include=\"float64\").columns\n",
    "print(float_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da2bff6",
   "metadata": {},
   "source": [
    "<a id=\"missing\"></a>\n",
    "# <b><span style='color:#ff6ea3'>Step 5 |</span><span style='color:purple'>  Missing Value Treatment</span></b>\n",
    "[Table of Contents](#contents_tabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f777883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in the dataset\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4a4e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64f1b5e",
   "metadata": {},
   "source": [
    "### Filling the null values with the averages of a particular category\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac585159",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Age at Diagnosis'].fillna(int(df['Age at Diagnosis'].mean()), inplace=True) \n",
    "df['Lymph nodes examined positive'].fillna(int(df['Lymph nodes examined positive'].mean()), inplace=True)\n",
    "df['Mutation Count'].fillna(int(df['Mutation Count'].mean()), inplace=True) \n",
    "df['Tumor Size'].fillna(int(df['Tumor Size'].mean()), inplace=True) \n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a3e16a",
   "metadata": {},
   "source": [
    "### The dropna() method removes the rows that contains NULL values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7bbe16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= df.dropna()\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b426ef10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_new.dtypes\n",
    "df.dtypes\n",
    "df['Age at Diagnosis']=df['Age at Diagnosis'].astype(int)\n",
    "df['Lymph nodes examined positive']=df['Lymph nodes examined positive'].astype(int)\n",
    "df['Mutation Count']=df['Mutation Count'].astype(int)\n",
    "df['Tumor Size']=df['Tumor Size'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de40837a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43359f63",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "83d575f2",
   "metadata": {},
   "source": [
    "<a id=\"encoding\"></a>\n",
    "# <b><span style='color:#ff6ea3'>Step 6 |</span><span style='color:purple'> Categorical Features Encoding</span></b>\n",
    "[Table of Contents](#contents_tabel)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9294ac40",
   "metadata": {},
   "source": [
    "## Label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea332c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat = df.select_dtypes(object)\n",
    "df_num = df.select_dtypes(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8d26c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea86b4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83832ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_cat:\n",
    "    le = LabelEncoder()\n",
    "    df_cat[col]= le.fit_transform(df_cat[col])\n",
    "df_cat.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978b7ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_new = [df_cat] + [df_num]\n",
    "df_new = pd.concat([df_cat, df_num], axis=1, join='inner')\n",
    "df_new\n",
    "for col in df_new:\n",
    "    df_new = df_new.astype(int) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fa4dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7469efa5",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<a id=\"eda\"></a>\n",
    "# <p style=\"background-color:purple; font-family:calibri; color:white; font-size:150%; text-align:center; border-radius:15px 50px;\">Step 7 | EDA</p>\n",
    "\n",
    " [Table of Contents](#contents_tabel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81015e2e",
   "metadata": {},
   "source": [
    "For our Exploratory Data Analysis (EDA), we'll take it in two main steps:\n",
    "\n",
    "1. Univariate Analysis: Here, we'll focus on one feature at a time to understand its distribution and range.\n",
    "\n",
    "2. Bivariate Analysis: In this step, we'll explore the relationship between each feature and the target variable. This helps us figure out the importance and influence of each feature on the target outcome.\n",
    "\n",
    "With these two steps, we aim to gain insights into the individual characteristics of the data and also how each feature relates to our main goal: predicting the target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6d196a",
   "metadata": {},
   "source": [
    "<a id=\"univariate\"></a>\n",
    "# <b><span style='color:#ff6ea3'>Step 7.1 |</span><span style='color:purple'> Univariate Analysis</span></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0824867c",
   "metadata": {},
   "source": [
    "We undertake univariate analysis on the dataset's features, based on their datatype:\n",
    "\n",
    "1. For continuous data: We employ histograms to gain insight into the distribution of each feature. This allows us to understand the central tendency, spread, and shape of the dataset's distribution.\n",
    "\n",
    "2. For categorical data: Bar plots are utilized to visualize the frequency of each category. This provides a clear representation of the prominence of each category within the respective feature.\n",
    "\n",
    "By employing these visualization techniques, we're better positioned to understand the individual characteristics of each feature in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e0873d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58d5bc1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Filter out continuous features for the univariate analysis\n",
    "df_continuous = df[continuous_features]\n",
    "\n",
    "# Set up the subplot\n",
    "fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(15, 10))\n",
    "\n",
    "# Loop to plot histograms for each continuous feature\n",
    "for i, col in enumerate(df_continuous.columns):\n",
    "    x = i // 2\n",
    "    y = i % 2\n",
    "    values, bin_edges = np.histogram(df_continuous[col], \n",
    "                                     range=(np.floor(df_continuous[col].min()), np.ceil(df_continuous[col].max())))\n",
    "    \n",
    "    graph = sns.histplot(data=df_continuous, x=col, bins=bin_edges, kde=True, ax=ax[x, y],\n",
    "                         edgecolor='black', color='purple', alpha=0.6)\n",
    "    ax[x, y].set_xlabel(col, fontsize=15)\n",
    "    ax[x, y].set_ylabel('Count', fontsize=12)\n",
    "    ax[x, y].set_xticks(np.round(bin_edges, 1))\n",
    "    ax[x, y].set_xticklabels(ax[x, y].get_xticks(), rotation=45)\n",
    "    ax[x, y].grid(color='lightgrey')\n",
    "    \n",
    "plt.suptitle('Distribution of Continuous Variables', fontsize=20)\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=0.92)\n",
    "plt.show()\n",
    "    \n",
    "   \n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2fbb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set up the subplot\n",
    "fig, ax = plt.subplots(nrows=15, ncols=2, figsize=(10,30))\n",
    "nrows=15 \n",
    "ncols=2\n",
    "# Loop to plot histograms for categorical feature\n",
    "# Loop to plot bar charts for each categorical feature in the 4x2 layout\n",
    "for i, col in enumerate(df_cat):\n",
    "    row = i // 2\n",
    "    col_idx = i % 2\n",
    "    \n",
    "    # Calculate frequency percentages\n",
    "    value_counts = df_new[col].value_counts(normalize=True).mul(100).sort_values()\n",
    "    \n",
    "    # Plot bar chart\n",
    "    value_counts.plot(kind='barh', ax=ax[row, col_idx], width=0.8, color='purple')\n",
    "    \n",
    "    # Add frequency percentages to the bars\n",
    "    for index, value in enumerate(value_counts):\n",
    "        ax[row, col_idx].text(value, index, str(round(value, 1)) + '%', fontsize=10, weight='bold', va='center')\n",
    "    \n",
    "    ax[row, col_idx].set_xlim([0, 95])\n",
    "    ax[row, col_idx].set_xlabel('Frequency Percentage', fontsize=10)\n",
    "    ax[row, col_idx].set_title(f'{col}', fontsize=10)\n",
    "ax = ax.flatten()\n",
    "ax[i].axis('off')\n",
    "plt.suptitle('Distribution of Categorical Variables', fontsize=22)\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=0.95)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d9be04",
   "metadata": {},
   "source": [
    "<a id=\"bivariate\"></a>\n",
    "# <b><span style='color:#ff6ea3'>Step 7.2 |</span><span style='color:purple'> Bivariate Analysis</span></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1267ad01",
   "metadata": {},
   "source": [
    "<a id=\"num_target\"></a>\n",
    "### <b><span style='color:#ff6ea3'>Step 7.2.1 |</span><span style='color:purple'> Numerical Features vs Overall Survival Status</span></b>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5821957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set color palette\n",
    "sns.set_palette(['#ff6ea3', 'purple'])\n",
    "\n",
    "# Create the subplots\n",
    "fig, ax = plt.subplots(len(continuous_features), 2, figsize=(8,10), gridspec_kw={'width_ratios': [1, 2]})\n",
    "\n",
    "# Loop through each continuous feature to create barplots and kde plots\n",
    "for i, col in enumerate(continuous_features):\n",
    "    # Barplot showing the mean value of the feature for each target category\n",
    "    graph = sns.barplot(data=df_new, x=\"Overall Survival Status\", y=col, ax=ax[i,0])\n",
    "    \n",
    "    # KDE plot showing the distribution of the feature for each target category\n",
    "    sns.kdeplot(data=df[df_new[\"Overall Survival Status\"]==0], x=col, fill=True, linewidth=2, ax=ax[i,1], label='0')\n",
    "    sns.kdeplot(data=df[df_new[\"Overall Survival Status\"]==1], x=col, fill=True, linewidth=2, ax=ax[i,1], label='1')\n",
    "    ax[i,1].set_yticks([])\n",
    "    ax[i,1].legend(title='Overall Survival (Months)', loc='upper right')\n",
    "    \n",
    "    # Add mean values to the barplot\n",
    "    for cont in graph.containers:\n",
    "        graph.bar_label(cont, fmt='         %.3g')\n",
    "        \n",
    "# Set the title for the entire figure\n",
    "plt.suptitle('Continuous Features vs Overall Survival Status', fontsize=20)\n",
    "plt.tight_layout()                     \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1519c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,15))\n",
    "plt.title('Correlation of Attributes', y=1.05, size=25)\n",
    "sns.heatmap(df_new.corr(), cmap='plasma',annot=True,  cbar=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247dd670",
   "metadata": {},
   "source": [
    "____\n",
    "<a id=\"cat_target\"></a>\n",
    "### <b><span style='color:#ff6ea3'>Step 7.2.2 |</span><span style='color:purple'> Categorical Features vs Overall Survival Status</span></b>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681d1be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove 'Overall Survival Status' from the categorical_features\n",
    "df_cat1 = [feature for feature in df_cat if feature != 'Overall Survival Status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f806a86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=15, ncols=2, figsize=(10,30)) # Width=10 inches, Height=30 inches\n",
    "\n",
    "for i,col in enumerate(df_cat1):\n",
    "    \n",
    "    # Create a cross tabulation showing the proportion of purchased and non-purchased loans for each category of the feature\n",
    "    cross_tab = pd.crosstab(index=df_new[col], columns=df_new['Overall Survival Status'])\n",
    "    \n",
    "    # Using the normalize=True argument gives us the index-wise proportion of the data\n",
    "    cross_tab_prop = pd.crosstab(index=df_new[col], columns=df_new['Overall Survival Status'], normalize='index')\n",
    "\n",
    "    # Define colormap\n",
    "    cmp = ListedColormap(['#ff6ea3', 'purple'])\n",
    "    \n",
    "    # Plot stacked bar charts\n",
    "    x, y = i//2, i%2\n",
    "    cross_tab_prop.plot(kind='bar', ax=ax[x,y], stacked=True, width=0.8, colormap=cmp,\n",
    "                        legend=False, ylabel='Proportion', sharey=True)\n",
    "    \n",
    "    \n",
    "    # Add legend\n",
    "    ax[x,y].legend(title='Overall Survival Status', loc='best', fontsize=8, ncol=2)\n",
    "    # Set y limit\n",
    "    ax[x,y].set_ylim([0,1.12])\n",
    "    # Rotate xticks\n",
    "    ax[x,y].set_xticklabels(ax[x,y].get_xticklabels(), rotation=0)\n",
    "\n",
    "plt.tight_layout()                     \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e442db93",
   "metadata": {},
   "source": [
    "<a id=\"preprocessing\"></a>\n",
    "# <p style=\"background-color:purple; font-family:calibri; color:white; font-size:150%; text-align:center; border-radius:15px 50px;\">Step 8 | Data Preprocessing</p>\n",
    " [Table of Contents](#contents_tabel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f8e15f",
   "metadata": {},
   "source": [
    "<a id=\"outlier\"></a>\n",
    "# <b><span style='color:#ff6ea3'>Step 8.1 |</span><span style='color:purple'> Outlier Treatment</span></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29edf27b",
   "metadata": {},
   "source": [
    "### IQR method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fa68a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_features\n",
    "Q1 = df[continuous_features].quantile(0.25)\n",
    "Q3 = df[continuous_features].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "outliers_count_specified = ((df[continuous_features] < (Q1 - 1.5 * IQR)) | (df[continuous_features] > (Q3 + 1.5 * IQR))).sum()\n",
    "outliers_count_specified\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9fbd86",
   "metadata": {},
   "source": [
    "#### Upon identifying outliers for the specified continuous features, we found the following:\n",
    "    Age at Diagnosis                   1\n",
    "    Lymph nodes examined positive    120\n",
    "    Mutation Count                    31\n",
    "    Tumor Size                        81"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1fab16",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_new:\n",
    "    df_new= df_new.astype(int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e020ced",
   "metadata": {},
   "source": [
    "<a id=\"transform\"></a>\n",
    "# <b><span style='color:#ff6ea3'>Step 8.2 |</span><span style='color:purple'> Transforming Skewed Features</span></b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4200249f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for col in df_num:\n",
    "    print(col)\n",
    "    print(skew(df_num[col]))\n",
    "    \n",
    "    plt.figure()\n",
    "    sns.distplot(df_num[col])\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f51ede1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the features (X) and the output labels (y)\n",
    "X = df_new.drop('Overall Survival Status', axis=1)\n",
    "y = df_new['Overall Survival Status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63ca8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e00be6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317e85c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the distribution of the continuous features\n",
    "fig, ax = plt.subplots(2, 4, figsize=(15,10))\n",
    "\n",
    "# Original Distributions\n",
    "for i, col in enumerate(continuous_features):\n",
    "    sns.histplot(X_train[col], kde=True, ax=ax[0,i], color='#ff826e').set_title(f'Original {col}')\n",
    "    \n",
    "\n",
    "# Applying Box-Cox Transformation\n",
    "# Dictionary to store lambda values for each feature\n",
    "lambdas = {}\n",
    "\n",
    "for i, col in enumerate(continuous_features):\n",
    "    # Only apply box-cox for positive values\n",
    "    if X_train[col].min() > 0:\n",
    "        X_train[col], lambdas[col] = boxcox(X_train[col])\n",
    "        # Applying the same lambda to test data\n",
    "        X_test[col] = boxcox(X_test[col], lmbda=lambdas[col]) \n",
    "        sns.histplot(X_train[col], kde=True, ax=ax[1,i], color='purple').set_title(f'Transformed {col}')\n",
    "    else:\n",
    "        sns.histplot(X_train[col], kde=True, ax=ax[1,i], color='green').set_title(f'{col} (Not Transformed)')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215f9d54",
   "metadata": {},
   "source": [
    "<a id=\"survival\"></a>\n",
    "# <p style=\"background-color:purple; font-family:calibri; color:white; font-size:150%; text-align:center; border-radius:15px 50px;\">Step 9 | Survival Analysis</p>\n",
    "\n",
    " [Table of Contents](#contents_tabel)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3282ae59",
   "metadata": {},
   "source": [
    "<a id=\"kp\"></a>\n",
    "# <b><span style='color:#ff6ea3'>Step 9.1 |</span><span style='color:purple'> Kaplan-Meier Survival Curve</span></b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bc328b",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = df_new[\"Overall Survival (Months)\"]\n",
    "E = df_new[\"Overall Survival Status\"]\n",
    "plt.hist(T, bins = 100)\n",
    "plt.show()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be188817",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "kmf = KaplanMeierFitter()\n",
    "kmf.fit(durations = T, event_observed = E)\n",
    "kmf.plot_survival_function()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fafc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmf.survival_function_.plot()\n",
    "plt.title('Survival function')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293df4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = pd.concat([df_cat, df_num], axis=1, join='inner')\n",
    "df_new\n",
    "for col in df_new:\n",
    "    df_new = df_new.astype(int) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb45554",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.subplot(111)\n",
    "m = (df_new[\"Chemotherapy\"] == 0)\n",
    "kmf.fit(durations = T[m], event_observed = E[m], label = \"yes\")\n",
    "kmf.plot_survival_function(ax = ax)\n",
    "kmf.fit(T[~m], event_observed = E[~m], label = \"no\")\n",
    "kmf.plot_survival_function(ax = ax, at_risk_counts = True)\n",
    "plt.title(\"Survival on the basis of Chemotherapy\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e45439",
   "metadata": {},
   "source": [
    "<a id=\"dt\"></a>\n",
    "# <p style=\"background-color:purple; font-family:calibri; color:white; font-size:150%; text-align:center; border-radius:15px 50px;\">Step 10 | Decision Tree Model Building</p>\n",
    " [Table of Contents](#contents_tabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4974188",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, roc_auc_score\n",
    " \n",
    "from IPython.display import Image  \n",
    "from sklearn.tree import export_graphviz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7505272f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the base DT model\n",
    "dt_base = DecisionTreeClassifier(random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f020382",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_clf_hyperparameters(clf, param_grid, X_train, y_train, scoring='recall', n_splits=3):\n",
    "    '''\n",
    "    This function optimizes the hyperparameters for a classifier by searching over a specified hyperparameter grid. \n",
    "    It uses GridSearchCV and cross-validation (StratifiedKFold) to evaluate different combinations of hyperparameters. \n",
    "    The combination with the highest recall for class 1 is selected as the default scoring metric. \n",
    "    The function returns the classifier with the optimal hyperparameters.\n",
    "    '''\n",
    "    \n",
    "    # Create the cross-validation object using StratifiedKFold to ensure the class distribution is the same across all the folds\n",
    "    cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=0)\n",
    "\n",
    "    # Create the GridSearchCV object\n",
    "    clf_grid = GridSearchCV(clf, param_grid, cv=cv, scoring=scoring, n_jobs=-1)\n",
    "\n",
    "    # Fit the GridSearchCV object to the training data\n",
    "    clf_grid.fit(X_train, y_train)\n",
    "\n",
    "    # Get the best hyperparameters\n",
    "    best_hyperparameters = clf_grid.best_params_\n",
    "    \n",
    "    # Return best_estimator_ attribute which gives us the best model that has been fitted to the training data\n",
    "    return clf_grid.best_estimator_, best_hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4801c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter grid for DT\n",
    "param_grid_dt = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [2,3],\n",
    "    'min_samples_split': [2, 3, 4],\n",
    "    'min_samples_leaf': [1, 2]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69360a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function for hyperparameter tuning\n",
    "best_dt, best_dt_hyperparams = tune_clf_hyperparameters(dt_base, param_grid_dt, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a175db9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter\n",
    "grid_param = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth' : range(2,32,1),\n",
    "    'min_samples_leaf' : range(1,10,1),\n",
    "    'min_samples_split': range(2,10,1),\n",
    "    'splitter' : ['best', 'random']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfaaf4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('DT Optimal Hyperparameters: \\n', best_dt_hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb5a401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the optimized model on the train data\n",
    "print(classification_report(y_train, best_dt.predict(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2fa6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the optimized model on the train data\n",
    "print(classification_report(y_train, best_dt.predict(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5107fa8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the Confusion Matrix for Random Forest Algorithm\n",
    "cm_dt = confusion_matrix(y_test,best_dt.predict(X_test))\n",
    "plt.figure(figsize=(1.8, 1.8))\n",
    "sns.set_context('notebook',font_scale = 0.5)\n",
    "sns.heatmap(cm_dt,annot=True,fmt='d', cmap=\"Oranges\", cbar=False)\n",
    "plt.title('Decision Tree Confusion Matrix');\n",
    "plt.xlabel(\"Predicted_Value\")\n",
    "plt.ylabel(\"True_Value\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867e6125",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, y_test, model_name):\n",
    "    \"\"\"\n",
    "    Evaluates the performance of a trained model on test data using various metrics.\n",
    "    \"\"\"\n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Get classification report\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    \n",
    "    # Extracting metrics\n",
    "    metrics = {\n",
    "        \"precision_0\": report[\"0\"][\"precision\"],\n",
    "        \"precision_1\": report[\"1\"][\"precision\"],\n",
    "        \"recall_0\": report[\"0\"][\"recall\"],\n",
    "        \"recall_1\": report[\"1\"][\"recall\"],\n",
    "        \"f1_0\": report[\"0\"][\"f1-score\"],\n",
    "        \"f1_1\": report[\"1\"][\"f1-score\"],\n",
    "        \"macro_avg_precision\": report[\"macro avg\"][\"precision\"],\n",
    "        \"macro_avg_recall\": report[\"macro avg\"][\"recall\"],\n",
    "        \"macro_avg_f1\": report[\"macro avg\"][\"f1-score\"],\n",
    "        \"accuracy\": accuracy_score(y_test, y_pred)\n",
    "    }\n",
    "    \n",
    "    # Convert dictionary to dataframe\n",
    "    df = pd.DataFrame(metrics, index=[model_name]).round(2)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554d35b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dt_evaluation = evaluate_model(best_dt, X_test, y_test, 'DT')\n",
    "dt_evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f29a7e5",
   "metadata": {},
   "source": [
    "## ROC-AUC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d262e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_base.fit(X_train, y_train)\n",
    "y_pred_prob_dt = dt_base.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791105dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_dt = roc_auc_score(y_test, y_pred_prob_dt)\n",
    "print(f'Decision Tree ROC-AUC Score: {roc_auc_dt:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36bbc3ff",
   "metadata": {},
   "source": [
    "<a id=\"rf\"></a>\n",
    "# <p style=\"background-color:purple; font-family:calibri; color:white; font-size:150%; text-align:center; border-radius:15px 50px;\">Step 11 | Random Forest Model Building</p>\n",
    "\n",
    "⬆️ [Table of Contents](#contents_tabel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fd32eb",
   "metadata": {},
   "source": [
    "<a id=\"rf_base\"></a>\n",
    "# <b><span style='color:#ff826e'>Step 11.1 |</span><span style='color:purple'> RF Base Model Definition</span></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c171f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_base = RandomForestClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11eeab84",
   "metadata": {},
   "source": [
    "____\n",
    "<a id=\"rf_hp\"></a>\n",
    "# <b><span style='color:#ff826e'>Step 11.2 |</span><span style='color:purple'> RF Hyperparameter Tuning</span></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5277a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_rf = {\n",
    "    'n_estimators': [10, 30, 50, 70, 100],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [2, 3, 4],\n",
    "    'min_samples_split': [2, 3, 4, 5],\n",
    "    'min_samples_leaf': [1, 2, 3],\n",
    "    'bootstrap': [True, False]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a907353",
   "metadata": {},
   "source": [
    "____\n",
    "<a id=\"rf_eval\"></a>\n",
    "# <b><span style='color:#ff826e'>Step 11.3 |</span><span style='color:purple'> RF Model Evaluation</span></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53a67e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the tune_clf_hyperparameters function to get the best estimator\n",
    "\n",
    "best_rf, best_rf_hyperparams = tune_clf_hyperparameters(rf_base, param_grid_rf, X_train, y_train)\n",
    "print('RF Optimal Hyperparameters: \\n', best_rf_hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c04e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the optimized model on the train data\n",
    "print(classification_report(y_train, best_rf.predict(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6336fc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the optimized model on the test data\n",
    "print(classification_report(y_test, best_rf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ad5a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_evaluation = evaluate_model(best_rf, X_test, y_test, 'RF')\n",
    "rf_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d3788a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the Confusion Matrix for Random Forest Algorithm\n",
    "cm_rf = confusion_matrix(y_test,best_rf.predict(X_test))\n",
    "plt.figure(figsize=(1.8, 1.8))\n",
    "sns.set_context('notebook',font_scale = 0.5)\n",
    "sns.heatmap(cm_rf,annot=True,fmt='d', cmap=\"Oranges\", cbar=False)\n",
    "plt.title('Random Forest Confusion Matrix');\n",
    "plt.xlabel(\"Predicted_Value\")\n",
    "plt.ylabel(\"True_Value\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df655cef",
   "metadata": {},
   "source": [
    "## ROC-AUC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335db5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_base.fit(X_train, y_train)\n",
    "y_pred_prob_rf = rf_base.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd812acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_dt = roc_auc_score(y_test, y_pred_prob_dt)\n",
    "print(f'Random Forest ROC-AUC Score: {roc_auc_dt:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f51a534",
   "metadata": {},
   "source": [
    "<a id=\"logistic\"></a>\n",
    "# <p style=\"background-color:purple; font-family:calibri; color:white; font-size:150%; text-align:center; border-radius:15px 50px;\">Step 12 | Logistic Regression Model Building</p>\n",
    "\n",
    "⬆️ [Table of Contents](#contents_tabel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a077e9fc",
   "metadata": {},
   "source": [
    "____\n",
    "<a id=\"logistic_base\"></a>\n",
    "# <b><span style='color:#ff826e'>Step 12.1 |</span><span style='color:purple'> Logistic Base Model Definition</span></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f222a586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the base logistic model and set up the pipeline with scaling\n",
    "logistic_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('LR', LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f376c7",
   "metadata": {},
   "source": [
    "____\n",
    "<a id=\"logistic_hp\"></a>\n",
    "# <b><span style='color:#ff826e'>Step 12.2 |</span><span style='color:purple'> Logistic Hyperparameter Tuning</span></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e07a529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter grid for Logistic Regression\n",
    "# penalty - determines the regularization, and helps prevent overfitting by adding a penalty to the optimization objective.\n",
    "# 'l1' refers to Lasso regularization, and 'l2' refers to Ridge regularization\n",
    "# 'C' - inverse of the regularization strength, smaller values specify stronger regularization\n",
    "# 'solver' - algorithm used for optimization in LR,  'liblinear' is suitable for small datasets, 'saga' for larger dataset\n",
    "param_grid_logistic = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'solver': ['liblinear']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6cd1db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_base=LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8490704c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function for hyperparameter tuning with logistic regression\n",
    "best_logistic, best_logistic_hyperparams = tune_clf_hyperparameters(logistic_base, param_grid_logistic, X_train, y_train)\n",
    "\n",
    "# Print the optimal hyperparameters for logistic regression\n",
    "print('Logistic Regression Optimal Hyperparameters: \\n', best_logistic_hyperparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ec0644",
   "metadata": {},
   "source": [
    "____\n",
    "<a id=\"logistic_eval\"></a>\n",
    "# <b><span style='color:#ff826e'>Step 12.3 |</span><span style='color:purple'> Logistic Model Evaluation</span></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38061571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the optimized model on the train data\n",
    "print(classification_report(y_train, best_logistic.predict(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadb22db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the optimized model on the test data\n",
    "print(classification_report(y_test, best_logistic.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9eea81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_evaluation = evaluate_model(best_logistic, X_test, y_test, 'LR')\n",
    "logistic_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04521cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the Confusion Matrix for Random Forest Algorithm\n",
    "cm_lr = confusion_matrix(y_test,best_logistic.predict(X_test))\n",
    "plt.figure(figsize=(1.8, 1.8))\n",
    "sns.set_context('notebook',font_scale = 0.5)\n",
    "sns.heatmap(cm_lr,annot=True,fmt='d', cmap=\"Oranges\", cbar=False)\n",
    "plt.title('Logistic Regression Confusion Matrix');\n",
    "plt.xlabel(\"Predicted_Value\")\n",
    "plt.ylabel(\"True_Value\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79102e4b",
   "metadata": {},
   "source": [
    "<a id=\"svm\"></a>\n",
    "# <p style=\"background-color:purple; font-family:calibri; color:white; font-size:150%; text-align:center; border-radius:15px 50px;\">Step 13 | SVM Model Building</p>\n",
    "\n",
    "⬆️ [Table of Contents](#contents_tabel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc07f121",
   "metadata": {},
   "source": [
    "____\n",
    "<a id=\"svm_base\"></a>\n",
    "# <b><span style='color:#ff826e'>Step 13.1 |</span><span style='color:purple'> SVM Base Model Definition</span></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9722a092",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svm', SVC()) \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25079a3b",
   "metadata": {},
   "source": [
    "____\n",
    "<a id=\"svm_hp\"></a>\n",
    "# <b><span style='color:#ff826e'>Step 13.2 |</span><span style='color:purple'> SVM Hyperparameter Tuning</span></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b687e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_svm = {\n",
    "    'svm__C': [5],\n",
    "    'svm__kernel': ['linear', 'rbf', 'poly'],\n",
    "#     'svm__gamma': [2],\n",
    "#     'svm__degree': [2,3,4]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a93c863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function for hyperparameter tuning\n",
    "best_svm, best_svm_hyperparams = tune_clf_hyperparameters(svm_pipeline, param_grid_svm, X_train, y_train)\n",
    "print('SVM Optimal Hyperparameters: \\n', best_svm_hyperparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b76f0a",
   "metadata": {},
   "source": [
    "____\n",
    "<a id=\"svm_eval\"></a>\n",
    "# <b><span style='color:#ff826e'>Step 13.3 |</span><span style='color:purple'> SVM Model Evaluation</span></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c20db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the optimized model on the train data\n",
    "print(classification_report(y_train, best_svm.predict(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c352054e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the optimized model on the test data\n",
    "print(classification_report(y_test, best_svm.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac621f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_evaluation = evaluate_model(best_svm, X_test, y_test, 'SVM')\n",
    "svm_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20085de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the Confusion Matrix for Support Vector Classifier Algorithm\n",
    "cm_svc = confusion_matrix(y_test, best_svm.predict(X_test))\n",
    "plt.figure(figsize=(1.8,1.8))\n",
    "sns.set_context('notebook',font_scale = 0.5)\n",
    "sns.heatmap(cm_svc,annot=True,fmt='d', cmap=\"Oranges\", cbar=False)\n",
    "plt.title('Support Vector Confusion Matrix');\n",
    "plt.xlabel(\"Predicted_Value\")\n",
    "plt.ylabel(\"True_Value\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326ef3f6",
   "metadata": {},
   "source": [
    "<a id=\"conclusion\"></a>\n",
    "# <p style=\"background-color:purple; font-family:calibri; color:white; font-size:150%; text-align:center; border-radius:15px 50px;\">Step 14 | Conclusion</p>\n",
    "\n",
    " [Table of Contents](#contents_tabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc12162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the dataframes\n",
    "all_evaluations = [dt_evaluation, rf_evaluation, logistic_evaluation, svm_evaluation]\n",
    "results = pd.concat(all_evaluations)\n",
    "\n",
    "# Sort by 'recall_1'\n",
    "results = results.sort_values(by='recall_1', ascending=False).round(2)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb10c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort values based on 'recall_1'\n",
    "results.sort_values(by='recall_1', ascending=True, inplace=True)\n",
    "recall_1_scores = results['recall_1']\n",
    "\n",
    "# Plot the horizontal bar chart\n",
    "fig, ax = plt.subplots(figsize=(12, 7), dpi=70)\n",
    "ax.barh(results.index, recall_1_scores, color='purple')\n",
    "\n",
    "# Annotate the values and indexes\n",
    "for i, (value, name) in enumerate(zip(recall_1_scores, results.index)):\n",
    "    ax.text(value + 0.01, i, f\"{value:.2f}\", ha='left', va='center', fontweight='bold', color='Purple', fontsize=15)\n",
    "    ax.text(0.1, i, name, ha='left', va='center', fontweight='bold', color='white', fontsize=25)\n",
    "\n",
    "# Remove yticks\n",
    "ax.set_yticks([])\n",
    "\n",
    "# Set x-axis limit\n",
    "ax.set_xlim([0, 1.2])\n",
    "\n",
    "# Add title and xlabel\n",
    "plt.title(\"Recall for Positive Class across Models\", fontweight='bold', fontsize=22)\n",
    "plt.xlabel('Recall Value', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3cab6d",
   "metadata": {},
   "source": [
    "<a id=\"prediction\"></a>\n",
    "# <p style=\"background-color:purple; font-family:calibri; color:white; font-size:150%; text-align:center; border-radius:15px 50px;\">Step 15 | Prediction</p>\n",
    "\n",
    "[Table of Contents](#contents_tabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c920097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to make a prediction based on user input\n",
    "def predict(features):\n",
    "    return best_rf.predict(np.array(features).reshape(1, -1))\n",
    "\n",
    "# Define feature names\n",
    "feature_names =['Type of Breast Surgery', 'Cancer Type',\n",
    "       'Cancer Type Detailed', 'Cellularity', 'Chemotherapy',\n",
    "       'Pam50 + Claudin-low subtype', 'Cohort', 'ER status measured by IHC',\n",
    "       'ER Status', 'Neoplasm Histologic Grade',\n",
    "       'HER2 status measured by SNP6', 'HER2 Status',\n",
    "       'Tumor Other Histologic Subtype', 'Hormone Therapy',\n",
    "       'Inferred Menopausal State', 'Integrative Cluster',\n",
    "       'Primary Tumor Laterality', 'Nottingham prognostic index',\n",
    "       'Oncotree Code', 'Overall Survival (Months)', 'Overall Survival Status',\n",
    "       'PR Status', 'Radio Therapy', 'Relapse Free Status (Months)',\n",
    "       'Relapse Free Status', 'Sex', '3-Gene classifier subtype',\n",
    "       'Tumor Stage', \"Patient's Vital Status\", 'Age at Diagnosis',\n",
    "       'Lymph nodes examined positive', 'Mutation Count', 'Tumor Size'] \n",
    "\n",
    "# Create input widgets\n",
    "feature_widgets = [widgets.FloatText(value=0.0, description=f'{feature}:') for feature in feature_names]\n",
    "\n",
    "# Create a button for making predictions\n",
    "predict_button = widgets.Button(description=\"Predict\")\n",
    "\n",
    "# Output widget to display prediction\n",
    "output_widget = widgets.Output()\n",
    "\n",
    "# Function to handle button click event\n",
    "def on_button_click(b):\n",
    "    user_input = [float(widget.value) for widget in feature_widgets]\n",
    "    prediction = predict(user_input)\n",
    "\n",
    "    # Display the prediction using IPython.display\n",
    "    with output_widget:\n",
    "        display(HTML(f\"<b>Prediction:</b> {prediction[0]}\"))\n",
    "\n",
    "# Attach the button click event\n",
    "predict_button.on_click(on_button_click)\n",
    "\n",
    "# Display widgets and output area\n",
    "display(*feature_widgets, predict_button, output_widget)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486121d4",
   "metadata": {},
   "source": [
    "# Thank You"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
